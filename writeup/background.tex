%!TEX root = main.tex

% =====================
% CHAPTER
% ---------------------
% =====================
\chapter{Background}
This section reviews the background of Vehicle Routing Problem (\VRP) and Pickup Delivery Problem (\PDP). Classic and more modern heuristics for solving the \VRP\ and related problems are reviewed as well providing a review of real-world implementations and results. 

% =====================
% SECTION
% =====================
\section{\TSP\ introduction and history}
The traveling salesman problem can informally be defined as given $n$ points on a map provide a route through each of the $n$ points such that each point is only used once and the total distance travelled is minimized. The problem's name, traveling salesman, comes from the classic real-world example of the problem: a salesman is sent on a trip to visit $n$ cities. What is order should she visit the cities in, such that she covers the least distance? See figure \ref{fig:tsp_example}

\picscl{images/background.pdf}{Traveling Salesman Problem}{fig:tsp_example}{0.75}

\TSP\ is related to a classic graph theory problem, the Hamiltonian path. Hamiltonian circuits have been studied since 1856 by both Hamilton \cite{Hamilton:1856} and Kirkman \cite{Kirkman:1856}. The traveling salesman problem has been informally discussed probably for many years \cite{Schrijver} but didn't become actively studied until after 1928 where Menger, Whitney, Flood and Robinson produced much of the early results in the field. Robinson's RAND report \cite{Robinson:1949} might have been the first article to call the problem by the name it has since become known, the Traveling Salesman Problem.  

\begin{quote}
  The purpose of this note is to give a method for solving a problem related to the traveling salesman problem. One formulation is to find the shortest route for a salesman starting from Washington, visiting all the state capitals and then returning to Washington. More generally, to find the shortest closed curve containing $n$ given points in the plane.
\end{quote}

An early result was provided by Dantzig, Fulkerson, and  Johnson \cite{Dantzig:1954}. Their paper gave an exact method for solving a 49 city problem, a large number of cities for the time. Their algorithm used the cutting plane method to provide an exact solution. This approach has been the inspiration for many subsequent approaches, and is still the bedrock of algorithms that attempt to provide an exact solution.  

Karp's famous paper, Reducibility Among Combinatorial Problems, in 1972 showed that the Hamiltonian Circuit problem is NP-complete. This implied the NP-hardness of \TSP, and thus supplied the mathematical explanation for the apparent difficulty of finding optimal tours.

A generalization of \TSP is \MTSP, where multiple routes are allowed to be constructed (i.e. multiple salesman can be used to visit the cities). The pure \MTSP\ can trivially be turned into a \TSP by constructing a graph $G$ with $n - 1$ additional copies of the starting node to the graph and forbidding travel directly between each $n$ starting nodes. Note however that the pure formulation of \MTSP\ places no additional constraints on a route. In real life applications \MTSP\ is typically employed with additional constraints, such as each route should be of equal size (e.g. work should be balanced among the salesman), or no route should exceed a total distance or time (e.g. a anyone salesman shouldn't be asked to work more than 8 hours a day). 

\MTSP leads us naturally into the a class of problems derived from the Vehicle Routing Problem (\VRP). \VRP -- and it's family of related problems -- can be understood as being a combination of \MTSP\ along with  other constraints, which are in themselves often combinatorially hard problems.    

% =====================
% SECTION
% =====================
\section{\VRP\ introduction and history}
The Vehicle Routing Problem (\VRP) seeks to solve the problem of constructing routes for a fleet of vehicles. Each route takes the vehicle through a set of customers to deliver a good (or service) at different locations. The routes must be constructed such that all constraints are meet, classically, the vehicle's capacity isn't exceeded by the number of customers being serviced. The goal is to minimize the cost of distributing the goods, which typically has meant minimizing the distance travelled across all routes.

% The large number of real-world applications, both in North America and Europe, have widely shown that the use of computerized procedures for the distribution process planning produces substantial savings (generally 5\% to 20\%) in globabl transportation costs. http://books.google.co.nz/books?hl=en&lr=&id=TeMgA5S74skC&oi=fnd&pg=PR5&dq=vehicle+routing+problem+history&ots=AhY2KbKu40&sig=F-oubQFGcQzDw-RODKMXg2C-jX8#v=onepage&q=vehicle%20routing%20problem%20history&f=false

% ---

% \VRP\ is one of the most the studied combinator optimization problems. Hundreds of papers been written on it  
% 
% Out of \VRP\ comes a family of related problems. These attempt to model other constraints that are encountered in real-world applications of the \VRP. Classic problems have included: \VRP\ with Time Windows that introduces a time window constraints  against each customer, that the vehicle must arrive within. \VRP\ multiple depot, where the vehicles are displayed from multiple start points. \VRP\ with Pick   

\VRP\ was first formally defined by Dantzig and Ramser, in \cite{Dantzig:1959} and has remained an important problem in logistics and transport (the original name given to the problem presented by Dantzig and Ramser was The Truck Scheduling Problem). The Vehicle Routing Problem is closely related to two problems, the Multiple Traveling Salesman Problem \MTSP\ and the Bin Packing Problem \BPP.

% =====================
% Sub Section
\subsection{Exact Methods}

The first efforts were concerned with exact solutions, and proceeded using many of the same techniques brought to bear on \TSP. 
We follow Laporte and Nobert's survey \cite{LANO:87} and classify exact algorithms for the \VRP\ into three families: Direct tree search methods, Dynamic programming, and Integer linear programming.

The first classic Direct tree search results are due to Christolds and Ellison. Their 1969 paper in Operations Research Quarterly provided the first branch and bound algorithm for exactly solving the \VRP \cite{CE:1969}. Unfortunately it's time and memory requirements where such that it was only able to solve problems of up to 13 customers. This result was later improved upon by Christolds in 1976 by using a different branch model. This improvement allowed him to solve for up to 31 customers. 

Christofides, Mingozzi, and Toth, \cite{CMT:1981} provide a lower bound method that is sufficiently quick (in terms of runtime performance) to be used to as a lower bound for excluding nodes from the search tree. They used this method to provide solutions as for a number of problems containing between 15 to 25 customers. Laporte, Mercure and Nobert \cite{LMN:1986} used \MTSP\ as a relaxation of \VRP\ within a branch and bound framework to provide solutions for 'realisticly' sized problems containing up to 250 customers.  

The Dynamic Programming approach was first proposed for \VRP\ by Eilon, Watson-Gandy and Christofides (1971). Their approach allowed them to solve exactly for problems of 10 to 25 customers. Since then, Christofides has made improvements to this algorithm to solve exactly for problems up to 50 vertices large.

A Set Partitioning algorithm was given by Balinski, and Quandt in 1964 to produce exact \VRP\ solutions \cite{balinski:64}. The problem sets they used where very small however, having only between 5 to 15 customers. And even despite this they weren't able to produce an solution for some of the problems. However, taking their approach as a starting point many authors have been able to produce more powerful methods. Rao and Zionts (1968), Foster and Ryan (1976), Orloff (1976), Desrosiers, Soumis and Desrochers (1984), Agarwal, Mathur and Salkin (1989), and Desrochers, Desrosiers and Solomon (1990), have all extended the basic set partitioning algorithm, using the Column Generation method, to produce more practically useful results. 

Notwithstanding the above results, exact methods have been of more use in advancing theoretical understanding of \VRP\ than to providing solutions to real life problems. This can mostly be attributed to the fact that real-life \VRP\ instances often involve hundreds of customers, and involve richer constraints than are modeled in a simple \VRP.

% =====================
% Sub Section
\subsection{Classic Heuristics}

Classic \VRP\ heuristics can be classified into three families. Constructive heuristics; Two-phase heuristics, which again can be classified into two sub-families: cluster first and then route, and route first and then cluster; and Improvement methods.

\subsubsection{Constructive heuristics}

We start by looking at Constructive heuristics. Constructive heuristics build a solutions from the ground up. They typically provide a recipe for building each route, such that the total cost of all routes is minimized. An early and influential result was given by Clarke and Wright in their 1964 paper, Scheduling of vehicles from a central depot to a number of delivery points \cite{clark:1964}. In this paper they present a heuristic method for solving \VRP\ problems that improved upon Dantzig and Ramser's work -- it is commonly known as the Clarke-Wright heuristic. The heuristic is based on the simple process of combining routes (starting with each route containing a single customer) such that the combination reduces the overall cost (typically distance) while still producing feasible solutions.

The heuristic has been used to solve problems of up to 1000 customers with results often within 10\% of optimal using only a 180 seconds of runtime \cite{TV2001}. This classic algorithm has been extended by Gaskell (1967), Yellow (1970) and Paessens (1988), who have suggested alternatives to the savings formulas used by Clarke and Wright. These approaches typically introduce additional parameters to guide the algorithm towards selecting routes with geometric properties that are likely to produce better combinations.

Alkinkemer and Gavish provide an interesting variation on the basic savings heuristic \cite{AG:1991}. They use a matching algorithm to combine multiple routes in a step. To do this they construct a graph where each vertex represents a route, each edge represents a feasible saving, and the edge's weight represents the saving that can be realized by the merge of the two routes. The algorithm proceed by solving a maximum cost weighted matching of the graph.

A group of construction heuristics, know as Sequential Insertion Heuristics, had their first results due to Mole and Jameson \cite{MJ:1976}.

\subsubsection{Two-phase heuristics}
\label{twophaseheuristics}

We next look at two-phase heuristics. We start by looking at the cluster-first, route second sub-family. One of the foundational algorithms for this method is due to Gillett and Miller who provided a new approach called the Sweep Algorithm in their 1974 paper\cite{GM:1974}. This popularized the two-phase approach, although this method was suggested earlier by Wren in his 1971 book, and subsequently in Wren and Holliday's 1972 paper for Operations Research Quarterly. In this approach, a initial clustering phase is used to cluster the customers into a base set of routes. From here the routes are treated as separate \TSP\ and optimized accordingly. The two-phase approach typically doesn't prescribe a method for how the \TSP\ is solved and assumes that already developed \TSP\ methods can be used. The classic sweep algorithm uses a simple geometric method to cluster the customers. Routes are built by sweeping a ray, centered at the depot, clockwise around the space enclosing the problem's locations. The Sweep method is surprising effective and has been shown to solve several benchmark \VRP\ problems to within 2\% to 9\% of the best known solutions \cite{TV2001}.

== PIC OF SWEEP == 

Fisher and Jaikumas's 1981 paper builds upon the two-phase approach by providing a more sophisticated clustering method. They solve a General Assignment Problem to form the clusters instead. A limitation of their method is that the amount of vehicle routes must be fixed up front. Their method often produces results that are 1\% to 2\% better than similar results produced by the classic sweep algorithm \cite{TV2001}. 

Christofides, Mingozzi, and Toth expanded upon this approach in \cite{???} and proposed a method that uses a truncated branch and bound technique (similar to Christofiedes Exact method). At each step it builds a collection of feasible routes containing a customer $i$ for evaluation. It then evaluates each route and selects the route that the \TSP with the shortest distance can be produced from.

The Petal algorithm is a natural extension to the Sweep Algorithm. It was first proposed by Balinski and Quandt \cite{??} and then extended by Foster and Ryan \cite{??}. The basic process is to produce a collection of overlapping candidate routes (called petals) and then to solve a set partition problem to produce a feasible solution. As with other two-phase approaches it's assumed that the order of the customers within each routes is solved using any pick of existing \TSP heuristics. It has produced some competitive results for small solutions, but quickly becomes impractical where the set of candidate routes that must be considered is large.  

Lastly, there are route first, cluster second methods. The basic premise of these techniques are to first construct a "grand" \TSP\ tour such that all customers are visited. The second phase is then concerned with splitting this tour into feasible routes. Route first, cluster second methods are generally thought to be less competitive than other methods \cite{Laporte:1999}, although interestingly Haimovich and Rinnooy Kan have shown that if all customers have unit demand then a simple shortest path algorithm (which can be solved in polynomial time) can be used to produce a solution from a \TSP\ tour that is asymptotically optimal \cite{HK:1985}.

\subsubsection{Iterative Improvement Heuristics}

Iterative Improvement methods follow a basic hilling climbing approach. They start with a solution, which may have been randomly generated, or produced by another heuristic technique, and then iteratively apply an operation to that solution to improve it. This continues until a local minimum is reached.

There have been a number of operations suggested. Christofides and Eilon gave one of the earliest iterative improvement methods in their paper \cite{CE:1969}. In this they made a simple change to the classic \TSP\ operation, 2-opt, increasing the amount of edges removed to three - the operation fittingly being called 3-opt. They found that their heuristics produced better results than the a 2-opt procedure could by itself. 

In general operations, such as 3-opt, that remove edges and then search for a more optimal recombination of components take \BIGO{n^y} where $y$ is the number of edges removed. A rich strain of research has been on producing operations that reduce the amount of recombinations that must be searched. Or presents an operation that has since come to be known as Or-opt \cite{Or:1976}. Or-opt is a restricted 3-opt. It searches for a relocation of all sets of 3 consecutive vertices (i.e. chains), such that an improvement is made. If an improvement can't be made then it tries again with chains of 2 consecutive vertices, and so on. Or-Opt has been shown to produce similar results to that of 3-opt, but with a running time of \BIGO{n^2}. More recently Renaud, Boctor, and Laptorte have presented a restricted version of 4-opt (in a similar vain to Or-Opt) that has a running time of \BIGO{wn^2} \cite{RBL:1996}. 

Iterative improvement heuristics are often used in combination with the other techniques. In this case they are run on the candidate solution after the initial heuristics has completed. However, for this purpose there is often a fine balance between producing an operation that improves a solution, and one that is sufficiently destructive enough to escape a local minimum.  Recently interest in iterative improvement heuristics has grown because of their use as part of meta-heuristic methods. 

We present a more detailed description of some classic improvement operations in section \ref{sec:cvhid}.

\subsection{Meta-Heuristics}

Meta-Heuristics are a broad collection of methods that make few or no assumptions about the type problem being solved. They provide a framework that allows for individual problems to be modeled and 'plugged in' to the meta-heuristic. Typically meta-heuristics take an approach where a candidate solution (or solutions) is initially produced and then is iteratively refined towards the optimal solution. Intuitively meta-heuristics can be thought of searching a problem's problem space. Each iteration searches the neighbourhood of the current candidate solution(s) looking for new candidate solutions that move closer to the goal. 

== INSERT PIC OF SEARCH SPACE ==

A limitation of meta-heuristics is that they aren't guaranteed to find an optimal solution (or even a good candidate). Indeed the theoretical underpinnings of what makes a meta-heuristic more effective than another is still poorly understood. Instead meta-heuristics in the literature tend to be tuned for specific problems and then validated empirically.

There have been a number of meta-heuristics produced for the \VRP\ in recent years. Many of the most competitive results produced in the last ten years have been from meta-heuristic approaches. We next review some of the more well known meta-heuristic results for \VRP.

\subsubsection{Simulated Annealing}

% from simulated annealing. With such an acceptance criteria, the temporary solution xt is always accepted if c(xt ) ≤ c(x), and accepted with probability e−(c(xt )−c(x))/T if c(x) < c(xt ). Here T > 0 is the current temperature. The temperature is initialized at T0 > 0 and is decreased gradually, for example by performing the update Tnew = αTold at each iteration, where 0 < α < 1 is a parameter. The idea is that T is relatively high initially, thus allowing deteriorating solutions to be accepted. As the search progresses T decreases and towards the end of the search only a few or no deteriorating solutions will be accepted. If

Simulated Annealing is inspired by the annealing process used in metallurgy. The algorithm starts with a candidate solution (which can be randomly selected) and then move to nearby solutions with a probability dependent on the quality of the solution and a global parameter $T$, that is reduced over the algorithm. By analogy to the metallurgy process $T$ represents the current temperature of the solution. Initially $T$ is high. This lets the algorithm free itself from any local minimum that it may be caught in. It is then cooled over time forcing the algorithm to converge to a new solution. 

One of the first results was given by Robuste, Daganzo and Souleyrette \cite{RDS:1990}. They define the search neighbourhood all solutions that can be obtained from the current solution by applying one of three operations: relocating part of a route to another position within the same route, and exchanging customers between two routes. They tested their solution on some large real-world instances of up to 500 customers. They self-reported some success with their method but as their test cases are unique no direct comparison is possible. 

Osman has given probably the best know Simulated Annealing results for \VRP \cite{Osman:1993}. His algorithm expands upon many areas of the basic Simulated Annealing approach. The method start by using the Clark and Wright algorithm to produce a starting position. It defines its neighbourhood as candidate solutions that can be searched by applying a $\lambda-interchange$ operation. $\lambda-interchange$ works by selecting two sequences (i.e. chains) of customers $S_p, S_q$ from two routes, $p$ and $q$, such that $\length{S_p}, \length{S_q} < \lambda$ (note the chains aren't necessary of the same length). The customers within each set are then exchanged until an exchange produces an infeasible solution. As the neighbourhood produced by $\lambda-interchange$ is typically large Osman restricts $\lambda$ to $\le 2$ and take the first move that provides an improvement. Osman also uses a sophisticated cooling schedule; his main change being that the temperature is cooled continuously while improvements are found, or if no improvement he resets the temperature (using $T_i = max(\frac{T_r}{2}, T_b)$, where $T_r$ is the reset temperature, and $T_b$ is temperature of the best solution found so far).

Although Simulated Annealing has produced some good results, and in many cases outperforms the classic heuristics (compare \cite{Laporte:1999} with \cite{GLP:1999}), it is not competitive with the tabu search implementation. 

\subsubsection{Genetic Algorithms}

Genetic Algorithms where first proposed in \cite{Holland:1975}. They've since been applied to many problem domains and are particularly well suited to applications that must work across a few distinct problems. In fact they were the first evolutionary inspired algorithms to be applied to combinatorial problems \cite{Potvin:2009}. The basic operation of a GA is as follows:

\begin{algorithm}
    Generate the initial population\\
    \While{termination condition not meet}{
        Evaluate the fitness of each individual\\
        Select the fittest pairs\\
        Mate pairs and produce next generation\\
        Mutate (optional)\\
    }
\end{algorithm}

In classic Genetic Algorithms each candidate solution is encoded as a binary string (i.e. chromosome). Each individual (i.e. candidate solution) is initially created randomly and used to seed the population. There are many techniques suggested in the literature for initially 'bootstraping' the population by making use of other heuristics to produce a stronger initial population, however special care must be taken with Genetic Algorithms to ensure that diversity is maintained within the population - otherwise there is a risk of premature convergence. 

Next the fittest individuals are selected from the population, and reproduction (crossover) and mutation operations are applyed to them to produce the next generation. A classic crossover operation takes individuals encoded as binary strings and splits them at one or two points. The parts are then recombined to form a new candidate solution. The idea being that the crossover produces a new candidate solution from two successful partial solutions. This process is repeated until a termination condition is meet (often a predetermined running time), or until the population has converged on a fitness.

Special consideration needs to be given to how discrete optimisation problems, such as the \VRP, are represented and how their operators are constructed. For instance, consider how the classic crossover operation would work on a \TSP path. When two parts of two separate solutions are combined they are likely to contain duplicates. Therefore it is more common for the \VRP\ (and the \TSP\ as well) to use a direct representation, rather than a binary encoding. In this instance the \VRP is represented as collection of sequences, each holdings a sequence of customers. The Genetic Algorithm then must use operators specially designed for this representation of the problem. 

Two commonly used crossover operators are Order Crossover (OX) and Edge Assembly Crossover (EAX). OX \cite{OSH:1987} operates by placing two cuts points within each route. The the substring between the two cut points is copied from the first parent directly into the offspring. The remainder of the string from the second parent is then copied to the offspring, but with any duplicates removed. This potentially leaves an incomplete solution, where not all the customers have been routed. The solutions is then "repaired" by inserting any remaining customers using an insertion heuristic.

== PIC OF OX Operator == 

Another common crossover operator is EAX. EAX was originally designed for the \TSP\ but has been adapted to the \VRP by \cite{Nagata:2007}. EAX operates using the following process:

\begin{enumerate}
    \item Combine the two candidate solutions into a single graph by merging each solutions edge sets.
    \item Create a partition set of the graph's cycles by alternately selecting an edge from each graph.
    \item Randomly select a subset of the cycles.
    \item Generate a (incomplete) child by taking one of the parents and removing all edges from the selected subset of cycles. Then add back in the edges from the parent that wasn't chosen. 
    \item Not all cycles in the child are connected to the route. Repair them by iteratively merging the disconnected cycles to the connected cycles.
\end{enumerate}

== PIC OF EAX ==

An alternative, and interesting, approach found in the literature is to instead encode a set of operations and parameters that are feed to another heuristic, that in turn produces a candidate solution. An early example of this was suggested by \cite{??} who encoded a ordering of the customers. The ordering is then feed into an Insertion heuristic to produce the actual candidate solutions.

An influential adaption of Genetic Algorithms for solving \VRPTW\ was given in \cite{TNJ:1991} with their GIDEON algorithm. GIDEON uses an approach inspired by the sweep heuristic (an overview is provided in section \ref{twophaseheuristics}). Routes are built by sweeping a ray, centered at the depot, clockwise around the space enclosing the problem's locations. Customers are collected into candidate routes based on a set of parameters that are refined by the GA. GIDEON uses the GA to evolve these parameters rather than to operate on the problem directly. Finally GIDEON uses a local search method to optimize customers with the routes, making use of the $\lambda-interchange$ operation (see section \ref{tabusearch} for a description of this operator).

Generally speaking Genetic Algorithms haven't been as competitive in \VRP\ as other meta-heuristics. However, more recently there have been two very promising application of Genetic Algorithms to \VRP. Nagata \cite{Nagata:2007} has adapted the EAX operator for with the \VRP. And Berger and Barkaoui have presented a Hybrid Genetic Algorithm called HGA-VRP in \cite{BM:2003}. HGA-VRP adapts a construction heuristic to be used as a crossover operator. The basic idea is that a set of routes are selected from each parent that are located close to each other. Customers are then removed from one parent and inserted into the second using an operation inspired by Solomon's construction heuristic for \VRPTW \cite{Solomon:1987}.

Both methods have reached the best known solution for a number of the classic \VRP\ benchmark instances by Christofides, Mingozzi and Toth \cite{CMT:1981} and are competitive with the best Tabu Search methods.

\subsubsection{Tabu Search}
\label{tabusearch}

Tabu Search follows the general approach shared by many meta-heuristics; it iteratively improving a candidate solution by searching for improvements within the current solution's neighborhood. Tabu search starts with a candidate solution, that may be generated randomly or by using another heuristic. Unlike Simulated Annealing, the best improvement within the current neighbourhood is always taken as the next move. This introduces the problem of cycling between candidate solutions. To overcome this Tabu Search introduces a list of solutions that have already been investigated and are forbidden as next moves (hence its name of Tabu List). 

The first instance of Tabu Search being used for \VRP\ is by Willard \cite{Willard:1989}. Willard's approach made use of the fact that \VRP\ instances can be transformed into a \MTSP\ instances and solved. The algorithm makes use of a combination of simple vertex exchange and relocate operations. Although opening the door for further research its results weren't competitive with the best classic heuristics. 

Osman gives a more competitive use of Tabu Search in \cite{Osman:1993}. As with his Simulated Annealing method he makes use of the $\lambda-interchange$ operation to define the search neighbourhood. Osman provides two alternative methods to control how much of the neighbourhood is searched to select the next move - Best-Improvement (BI) and First-Improvement (FI). Best-Improvement searches the entire neighbourhood and selects the move that is the most optimal. First-Improvement searches only until a move is found that is more optimal than the current position. This heuristic produces some competitive results that often out perform the classic heuristics. However it has been refined and improved upon by newer Tabu Search methods.

Toth and Vigo introduced the concept of Granular Tabu Search (GTS) \cite{GHL:1998}. Their method makes use of a process that removes moves from the neighbourhood that are unlikely to produce good results. They reintroduce these moves back into the process if the algorithm is stuck in a local minimum. Their idea follows from an existing idea known as candidate lists. Toth and Vigo's method has produced many competitive results.

Taillard gave a very successful application of Tabu Search in \cite{Taillard:1993}. Talliard's Tabu Search uses Or's $\lambda-interchange$ as it's neighbourhood structure. It borrows two novel concepts from \cite{GHL:1994}, the use of a more sophisticated tabu mechanism - the duration (or number of iterations) that an item is tabu for is chosen randomly, and a diversification strategy, where vertices that are frequently moved without giving an improvement are penalised. An novel aspect of Taillard's algorithm is it's decomposing of the problem into sub-problems. The problem is split into regions using a simple segmentation of the region centred about the depot (Taillard also provides an alternative approach for problems where the customers are evenly distributed around the depot). From here each subproblem is solved individually, with customers being exchanged between neighboring segments periodically. Taillard observes that exchanging customer beyond neighboring segments is unlikely to produce an improvement, so can safely be ignored. Taillard's method has produced some of the currently best known results for the standard Christofides, Mingozzi and Toth problem sets \cite{CMT:1981}. 

\subsubsection{Large Neighbourhood Search}

Large Neighbourhood Search (commonly abbreviated to LNS) was recently proposed as a heuristic by Shaw \cite{Shaw:1998}. Large Neighbourhood Search is a type heuristic belonging to the family known as Very Large Scale Neighbourhood search (VLSN)\footnote{LNS is somewhat confusingly named given that it a type of VLSN, and not a competing approach}. Very Large Scale Neighborhood search is based on a simple premise that rather than searching within a neighborhood of solutions that can be obtained from a single (and typically quite granular) operation, such as $2-opt$, it might be profitable to consider a much broader neighborhood; A neighbourhood of candidate solutions that are obtained from applying many simultaneous changes to the current solution. What distinguishes these heuristics from others is that the neighborhood under consideration is typically exponentially large, and sometimes infeasible to search. Therefore much attention is given to providing practical methods to search these neighborhoods. 

Large Neighbourhood Search uses a Destroy and Repair metaphor for how it searches within its neighbourhood. The basic operation is as follows.

\begin{algorithm}
   $x$ = an initial solution\\
   \While{termination condition not meet}{
      $x^t$ = $x$\\
      $destroy(x^t)$ \\
      $repair(x^t)$ \\
      \If {$x_t$ better than current solution}{
         $x = x_t$
      }
   }
   \KwResult{ $x$ }
\end{algorithm}

Firstly a starting position is generated. This can be done randomly or by using another heuristic. Then for each iteration of the algorithm a new position is generated by destroying part of the candidate solution and then by repairing it. If the new solution is better than the current solution, then this is selected as the new position and loop repeats. This can be seen as being a type of Very Large Scale Neighborhood because at each iteration the number of neighboring solutions that can be built from the partially destroyed solution is exponential on the size of the items removed (i.e. destroyed).

Obviously a key component of this approach are the functions used to destroy and repair the solution. Care must be given to how these functions are constructed. They must pinpoint an improving solution from a very large neighbourhood of candidates, while also providing enough degrees of freedom to escape local minimum.

Empiric evidence in the literature shows that even surprisingly simple functions can be effective (more effective in some cases) \cite{Shaw:1998}\cite{Ropke:2005}. In applications of Large Neighbourhood Search to \VRP\ a pair of simple operations are commonly used (alongside more complex ones) for the destroy and repair functions. Specifically, part of the candidate solution is destroyed by randomly selecting and removing $n$ customers. Then it is repaired by finding the least cost reinsertion points back into the solution for the $n$ customers.

Shaw applied Large Neighbourhood Search to \VRP\ in his original paper introducing the method\cite{Shaw:1998}. Shaw introduces a few novel approaches to the destroy and repair functions. His destroy function removes a set of 'related' customers. He defines related customer to be any two customers that share a similar geographic location, that are sequentially routed, or that share a number of similar constraints (such as overlapping time windows if times constraints are used). The idea of removing related customers, over simply removing random customers, is that related customers are more likely to be profitable exchanged (likewise unrelated customers are more likely to be reinserted back in their original positions). Shaw's repair function made use of a simply branch and bound method that finds the minimum cost reinsertion points within the partial solution. His results where immediately impressive and reached the many of the best known solutions on the Christofides, Mingozzi and Toth problems \cite{CMT:1981}.

More recently Ropke proposed an extension to the basic Large Neighbourhood Search process in \cite{Ropke:2005}. His method adds the concept of using a collection of destroy and repairs functions, rather than using a single pair. Which function to use is selected at each iteration based on it's previous performance. In this way the algorithm self adapts to using the most effective function to search the neighbourhood. 

Ropke makes use of several destroy functions. He uses a simple random removal heuristic, Shaw's removal heuristic, and a worst removal heuristic, which removes the most costly customers (in terms of that customer's contribution the routes overall cost). Likewise for insertion he makes use of several different functions. These include a simple greedy insertion heuristic, and a novel insertion method he calls the 'regret heuristic'. Informally the regret heuristic reinserts those customers first who are most impacted (in terms of increased cost) by not being inserted into their minimum positions. Specifically let $U$ be the set of customers to be reinserted. let $x_{ik} = \set{1,...,m}$ be a variable that gives the $k$'th lowest cost for inserting customer $i \in U$ into the partial solution. Now let $c_i^* = x_{i2} - x_{i1}$, in other words the cost difference between inserting customer $i$ into it's second best position and its first. Now in each iteration of the repair function choose a customer that maximizes:
\[
   \operatorname*{max}_{i \in U} c_i^*
\]

Ropke presents a series of results that show that his Large Neighbourhood Search is very competitive for solving the \VRP\ and a large number of related problems, \CVRP, \VRPTW, \PDPTW, and \DARP). Considering that Large Neighbourhood Search was only proposed in 1998 it has been very successful. In a short space of time it has attracted a large amount of research and has produced some of the most competitive results.

% RESULTS TABLE FROM VRP BOOK / PAPER

% – cluster first, route second (Fisher, Jaikumas, Net- works, 1981)
% – intra-route improvement methods (TSP heuristics)
% – inter-route improvement methods (λ-interchanges, Osman, 1993; cyclic exchanges, Thompson and Psaraf- fis, 1993; edge exchange schemes, Kindervater and Savelsbergh, 1997; ejection chains (Xu and Kelly, 1996; Rego and Roucairol, 1996; Rego, 1998); very large neighbourhood search (Ergun et al., 2003)
% – SERR (De Franceschi, Fischetti, Toth, working pa- per, 2004)
% --
% 1989 First tabu search implementation (Willard, M.Sc. thesis, Imperial College)
% 1991  First version of Taburoute (Gendreau, Hertz, Laporte, Tristan I Conference)
% 1993  Tabu search (Taillard, Networks)
% 1993 Simulated Annealing and tabu search (Osman, Annals of Operations Research)
% 1994  Taburoute (Gendreau, Hertz, Laporte, Management Science)
% 1995 Adaptive memory (Rochat, Taillard, Journal of Heuristics)
% 1996  Ejection chains (Rego, Roucairol, Meta-Heuristics: Theory and Applications)
% 9
% 2001 Unified tabu search algorithm (Cordeau, Laporte, Mercier, Journal of the Operational Research Society)
% 2002  Adaptive memory (Tarantilis, Kiranoudis, Annals of Operations Research)
% 2003  Granular tabu search (Toth, Vigo, INFORMS Journal on Computing)
% 2003 Very large neighbourhood search (Ergun, Orlin, Steele-Feldman, working paper, MIT)
% 2004 Deterministic annealing (Li, Golden, Wasil, Computers & Operations Research)
% 2004  Population search (Prins, Computers & Operations Research; Mester and Br ̈aysy, Computers & Opera- tions Research)
% 2004 Ant systems optimization (Reinmann, Doerner, Hartl, Computers & Operations Research)
% 2005  Attribute based hill climber heuristic (Derigs, Kaiser)

\section{An introduction to Swarm Intelligence}

% - PSO
% - Ant Colony
% - Bees Algorithm

% - TIMELINE OF CLASSIC RESULTS


% =====================
% SECTION
% =====================
\section{Classic \VRP\ heuristics in depth}
\label{sec:cvhid}

This section reviews some of the more common heuristics algorithms. BECAUSE THEY CAN BE USED AS IMPROVEMENT TECHNIQUES WHEN DESIGNING META-HEURISTICS

% ---------------------
\subsection{Nearest neighbour}
The most simple algorithm, this codifies the intuitive principle of constructing a solution by picking the job to the depot, then the closest job to this, and so on until a route is filled.

Formally the algorithm creates the sequence $R = \seq{v_0}$ and picks $v \in V$ such that $d_{0,i}$ is minimized. It repeat this until the route represented by $R$ is exceeds it capacity. Then a new route $R$ is constructed and the process is repeated with the remaining jobs. This continues until all jobs are allocated.

Although the Nearest Neighbour algorithm is simple to understand and implement it situations can occur where the performance is bad

% ---------------------
\subsection{Nearest insertion}

The algorithm was first proposed by ?

This algorithm slightly improves upon the previous algorithm. The algorithm proceeds much the same as the Nearest Neighbour algorithm but instead of considering only the previous node it considers the entire sequence of jobs route so far in $R$. It finds an insertion point along $R$ such that for job $v_k$ insertion between vertices $v_i, v_j$ the function $c_{ik} + c_{kj} - c_{ij}$ is minimized.

% ---------------------
\subsection{Clark and Wright algorithm}

Clark-Wright's widely known construction algorithm first appeared in \cite{clark:1964}. The algorithm uses a concept of \emph{savings}. The algorithm starts with a separate route for each customer: from depot, to customer, and back to the depot. A saving value is calculated for every pair of customers. The saving value is the distance saved by one customer being serviced directly after the other without returning to the depot in between -- in other words the savings gained by combining two partial routes. Routes are then merged based on the largest savings.

The algorithm comes in two flavours: sequential and parallel. The sequential version sequentially adds customers to a route until a route has reached capacity (or based on some other constraint such as maximum route length) and then produces the next. The parallel version builds each route in parallel. The parallel version out performs the sequential version in most cases\cite{Laporte:1999} and is the version considered in our approach.

The algorithm is surprising adaptable and has been extended to deal with more specialized vehicle routing problems were additional objectives and constraints must be considered. The algorithm's flexibility derives from its algebraic treatment of the problem rather than exploiting the problem's underlying spatial properties, as many of the two-phase algorithms do \ref{2phasealgorithms}. The algorithms savings formula can be adjusted to accommodate other objectives. An example of this is Solomon's equally ubiquitous algorithm \cite{Solomon:1987} which extends the Clark and Wright algorithm to cater for time constraints. 

The algorithm works as follows:

\begin{itemize}
	\item Prime the solution with routes $R = \set{x_0, x_i, x_0}$ for all jobs $x_i \in X$.
	\item For all $i,j$ calculate $s_{ij} = c_{i0} + c_{j0} - c_{ij}$.
	\item Process each $S_{ij}$ in descending order, find routes $r_1 \in R : r_1 = \set{0,...,x_i,x_0}$ and $r_2 \in R: r_2 = \set{0,x_j,...,0}$. Merge these together such that $R' = \set{0,...,x_i, x+j,...,0}$. Stop once capacity constraints or route length constraint is exceeded.
\end{itemize}

\picscl{images/background-cw.pdf}{Clark Wright Savings Algorithm}{fig:cw_savings}{0.75}

% ---------------------
\subsection{2-opt}

% ---------------------
\subsection{Or-opt}

% String Exchange + Cross

% ---------------------
\subsection{Osman-opt}






