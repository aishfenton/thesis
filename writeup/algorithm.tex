%!TEX root = main.tex

% =====================
% CHAPTER
% ---------------------
% =====================
\chapter{Algorithm}
\label{chap:algorithm}

This Chapter provides a detailed description of the Enhanced Bees Algorithm, the algorithm developed for this thesis, and its operation. We start by reviewing the objectives that the algorithm was designed to meet in Section \ref{sec:objectives}. In Section \ref{sec:problemrepresentation} we provide a description of how the algorithm internally represents the \VRP\ problem and its candidate solutions. Next in Section \ref{sec:enhancedbeesalgorithm} we provide a detailed description of the operation of the algorithm. Finally, in Section \ref{sec:searchneighbourhood} we describe the neighbourhood structures that are used by the algorithm to define its search space.

% =====================
% SECTION
% =====================
\section{Objectives}
\label{sec:objectives}

The Enhanced Bees Algorithm was built for use in a commercial setting. It was developed as part of a New Zealand Trade and Enterprise grant for the company \emph{vWorkApp Inc.}'s scheduling and dispatch software. Accordingly, different objectives were aimed for with its design (such as runtime performance) than are typically sought in the \VRP\ literature. The algorithm's objectives, in order of priority, are as follows:

\begin{enumerate}
   \item Ensure that all constraints are met. Specifically that the route's maximum duration is observed. 
   
   \item Have a good runtime performance. It is more desirable for the algorithm to produce a reasonable quality result quickly (within 60 seconds), than for it to produce a better result but require a longer processing time. Specifically if the algorithm could reach 5\% of the optimum value within 60 seconds then this would be sufficient. 

   \item Produce good quality results. Notwithstanding objective 2, the results produced must be close to the global optimum. 
   
   \item Have a design that lends itself to parallelisation and is able to make use of the additional processing cores available within modern hardware.
   
\end{enumerate}

% =====================
% SECTION
% =====================
\section{Problem Representation}
\label{sec:problemrepresentation}

The Enhanced Bees Algorithm represents the problem in a direct and straightforward manner. It proceeds by directly manipulating the candidate solution $\schd$, where $\schd$ is a set of routes $R \in \schd$, and each route contains an ordered sequence of customers $v_i \in R$ starting and ending at the depot vertex $v^d$.

\picscl{images/representation.pdf}{Shown is an example of a simple \VRP\ candidate solution as represented internally by the Enhanced Bees Algorithm.}{fig:representation}{0.66}

More general representations are sometimes used for meta-heuristics, as is commonly seen with Genetic Algorithms, as they allow the algorithm to be easily adapted to other combinatorial problems. However, this often comes at a cost of added complexity and inferior results\footnote{This occurs because the operators that act on the problem representation can no longer exploit information that is specific to the problem domain and must rely on general purpose operations instead.}. This algorithm was designed specifically for solving instances of the \VRP\ so the direct representation was chosen.

The algorithm makes use of a \emph{fitness} concept, common to many meta-heuristics, to describe the cost of the solution. The fitness function $f()$ includes terms for the distance (i.e.~cost) of the solution and penalties for breaking the capacity and maximum route duration constraints. The Enhanced Bees Algorithm uses penalties to encourage feasible solutions to be produced. Rather than outright barring infeasible solutions, the fitness function allows the algorithm some wriggle room to traverse through infeasible solutions on its way towards a feasible one.

Specifically $f()$ is defined as follows:

\begin{align}
   & c(R) = \sum_{i \in R} c_{i, i+1} \\
   & d(R) = max\left( \sum_{i \in R} d_i - q, 0 \right)  \\
   & t(R) = max\left( \sum_{i \in R} t_i + c(R) - t, 0 \right)  \\
   & f(\schd) = \sum_{R \in \schd} (\alpha c(R) + \beta d(R) + \gamma c(R))
\end{align}

Function $c(R)$ calculates the cost (i.e distance) of a given route, and function $d(R)$ calculates how overcapacity the given route is. We define overcapacity to be how much larger the sum of the route's demands, $d_i, i \in R$, are than the stated maximum allowable capacity $q$. Likewise function $t(R)$ calculates the overtime of a given route. A route's duration is calculated as being the sum of its customer's service times, $t_i, i \in R$, and its travel time. By convention the travel time is equal to the distance of the route. Function $t(R)$ then returns how much over the maximum allowable route duration, $t$. the duration is. Lastly, the fitness function $f()$ is the weighted sum of these three terms. Parameters $\alpha$, $\beta$, and $\gamma$ are used used to control how much influence each term has on determining the candidate solution's fitness.

For the purposes of benchmarking our algorithm (see Chapter \ref{chap:results}) we use a travel cost that is equal to the 2D Euclidian distance\footnote{Specifically, we use: $c_{ij} = \sqrt{(x_j-x_i)^2 + (y_j-y_i)^2}$} between the two points. For real life problem instance we have found that using a manhattan distance\footnote{Specifically, we use: $c_{ij} = (x_j-x_i)^2 + (y_j-y_i)^2$} often provides superior results. This is presumably due to the manhattan distance better modelling the road system within Auckland, which although not a strict grid, is still closer to one than the Euclidian distance models.

% =====================
% SECTION
% =====================
\section{Enhanced Bees Algorithm}
\label{sec:enhancedbeesalgorithm}

Our Algorithm is based on the \emph{Bees Algorithm} (see Section \ref{subsec:beesalgorithm} for an overview of the standard Bees Algorithm). The algorithm makes some changes to adapt the Bees Algorithm to the \VRP\ domain. An interesting aspect of the Bees Algorithm is that it covers a broad search area, minimising the risk of being stuck in a local optimum. It achieves this by randomly probing (or in the Bees Algorithm parlance, `scouting') many areas of the search space through its entire run. However, this approach isn't well suited to hard combinatorial problems, where a newly constructed solution, let alone a randomly generated one, is often far from optimal (for instance, the Clark Wright Savings heuristic still produces solutions that are up to 15\% from the global optimum and would require many operations to get close to optimal). We've adapted the Bees Algorithm so that many of its unique characteristics, such as its relative robustness, are maintained while working well with hard combinatorial problem, such as the \VRP.

The Enhanced Bees Algorithm can be summarised, at a high level, as follows:

\begin{algorithm}[H]
   \caption{Enhanced Bees Algorithm}
   $S$ = seedSites() \\

   \While{termination condition not met}{
      \For{$s_i \in S$}{
         explore($s_i$, $d$) \\
         \If{$i < \lambda$}{
            removeWorstSite \\
         }
      }
   }
\end{algorithm}

The algorithm maintains a collection of sites $S$, and each site $s_i \in S$ maintains a collection of bees, $B_i$. Each bee is a proxy to the problem domain that we are trying to solve. In our case this is the \VRP\ problem representation covered above.

Initially each site is seeded, such that each site, $s_i \in S$, contains a collection of bees $B_i$, and each bee has a corresponding \VRP\ candidate solution, $\schd$. Each candidate solution is initialised by seeding each route with a randomly chosen customer, which is then filled out using the insertion heuristic outlined in Section \ref{subsec:repairheuristic}. Each site is then, in turn, improved upon. This is achieved by iteratively exploring the neighbourhood of each site. The process used to explore each site is where the majority of the algorithm's processing takes place and where many of the interesting aspects of the algorithm come into play. The exploration process is covered in detail in sections \ref{sec:beemovement}, \ref{subsec:searchspacecoverage}, and \ref{sec:searchneighbourhood}.

The number of sites explored is reduced over the run of the algorithm. This borrows from the idea of a cooling schedule used in Simulated Annealing. Sites are reduced using the formula:

\begin{align}
   & S = S - s_w & \text{if $i \bmod{\lambda} \equiv 0$}
\end{align}

Where $s_w$ represents the worst site, in terms of fitness, $i$ represents the current iteration of the algorithm, and $\lambda$ represents the period of iterations with which the number of sites are reduced. Once the algorithm is complete the $\schd$ with the best overall fitness is returned as the answer.

In the next section we review in more detail each aspect of the algorithm. 

% ---------------------
\subsection{Bee Movement}
\label{sec:beemovement}

Bees are moved around the search space to look for improvements to the collection of candidate solutions being maintained. Each bee represents a candidate solution, $\schd$, so a valid bee move is any new candidate solution $\schd'$ that can be reached within the neighbourhood of $\schd$ (see Section \ref{sec:searchneighbourhood} for the operations under which the neighbourhood is defined).

\picscl{images/movement.pdf}{Three sites are shown along with their neighbourhoods. Site $i$ shows in more detail that each site maintains a list of the last $\epsilon$ most promising positions for exploration.}{fig:movement}{0.85}

A feature of our algorithm is that two Bees cannot occupy the same position. The algorithm maintains a register of the current positions occupied by each bee. We use the current fitness, $f(\schd)$, as a quick and simple representation of a bee's current position\footnote{This obviously will not work in circumstances where there is a reasonable likelihood of two candidate solutions, $\schd_i$ and $\schd_j$ having $f(\schd_i) = f(\schd_j)$. This isn't the case with the problem instances we have used in this thesis. However, this may need to be modified if the algorithm is to be used on more general problem instances.}. If a bee tries to occupy the same position as another bee (i.e.~they share the same candidate solution) then the bee trying to occupy that position is forced to explore the neighbourhood again and find another position. 

Enforcing the constraint that each bee must occupy a unique position has two benefits: it forces diversification between the bees and sites, hence encouraging a greater proportion of the search space to be explored; and it increases the chance of a local optimum being escaped, as a bee ensnared in the local optimum now forces the remainder of the hive to explore alternative positions. This feature has a similar intent and purpose to the tabu lists used by Tabu Search.

Another feature of the Enhanced Bees Algorithm is the role that sites play in concentrating exploration on certain areas of the search space. Each site maintains a list, $M = \seq{\schd_1,..., \schd_\epsilon}$, of the last $\epsilon$ best positions. Each $\schd_i \in M$ is then taken as a launching point for a site's bees to explore. $\theta$ bees are recruited for the exploration of each $\schd_i \in M$. Once all positions in $M$ have been explored then the best $\epsilon$ positions are again taken and used as the launching points for the site's next round of exploration. This exploration method has two purposes: firstly, it allows for a simple type of branching, as $\epsilon$ of the most promising positions that were traversed through on the way to the current position are also explored; secondly, it prevents cycling between promising solutions that are in close vicinity to each other.

Conversely, sites do not interact with each other, as each site maintains its own unique list of $\epsilon$ promising positions. The constraint that no two bees can occupy the same position ensures that each site covers a non overlapping area of the search space. In practice we have found that this is sufficient to encourage sites to diverge and explore distinct areas of the search space.    

% SEEDING EACH SITE WITH BEST POS SO FAR

% ---------------------
\subsection{Search Space Coverage}
\label{subsec:searchspacecoverage}

As mentioned above one of the unique aspects of the Bees Algorithm is its ability to produce robust results through probing a large area of the search space. However, this doesn't work well with hard combinatorial problems, where it cannot be ascertained quickly if an area in the search space shows promise or not. 

To overcome this limitation we instead use an approach inspired by Simulated Annealing's use of a cooling schedule. Bees are initially divided equally between each site $s_i \in S$, ensuring that each site is explored equally. Then every $\lambda$ period of iterations we reduce the number of sites maintained, such that $S = S - s_w$, where $s_w$ is the site with lowest fitness. We measure each site's fitness from the fitness of its best position found to date.

This process continues until a single site remains. We show experimentally in Chapter \ref{chap:results} that this process improves the robustness of the algorithm and produces better results overall than the standard Bees Algorithm. 

% =====================
% SECTION
% =====================
\section{Search Neighbourhood}
\label{sec:searchneighbourhood}

As discussed above, each bee seeks to improve upon its current fitness by exploring the local neighbourhood of the solution it represents. The Enhanced Bees Algorithm does this by applying a Large Neighbourhood Search (LNS) operator to its candidate solution $\schd$. The LNS operator differs from the more common \VRP\ operators in that a single operation applies many changes to the candidate solution $\schd$. This widens the neighbourhood of $\schd$ to encompass exponentially many candidate solutions. LNS navigates through the vast space it spans by selecting only those changes that have a high likelihood of improving the solution.

The LNS operation is comprised of two-phases: a destroy phase, and a repair phase. LNS's destroy phase typically involves removing a proportion of the customers from the solution. The Enhanced Bees Algorithm's destroy phase uses two heuristics along those lines: a somewhat intelligent heuristic that attempts to remove those customers that are more likely to be able to be recombined in a profitable way; and a simple random selection. These heuristics are covered in more detail in Section \ref{subsec:destroyheuristic} below. The second phase of LNS is used to repair the partial solution. Our algorithm uses a simple insertion heuristic that inserts the customers into those locations that that have the lowest insertion cost. This heuristic is covered more formally in Section \ref{subsec:repairheuristic} below.

% ---------------------
\subsection{Destroy Heuristic}
\label{subsec:destroyheuristic}

The Enhanced Bees Algorithm employs two destroy heuristics. The first simply selects $l$ customers randomly from a solution $\schd$ and removes these from their routes. The second is slightly more complicated and is due to Shaw~\cite{Shaw:1998}. Shaw's removal heuristic stochastically selects customers such that there is a higher likelihood of customers that are related to one another being removed. For our purposes we define \emph{related} to mean that for any two customers, $v_i, v_j \in V$, then either $v_i, v_j$ are geographically close to one another (i.e.~$c_{ij}$ is small), or that they share an adjacent position within the same route, $R = \seq{..., v_i, v_j, ...}$.

The rationale to removing related customers is that they are the most likely to be profitably exchanged with one another. Conversely, unrelated customers are more likely to be reinserted back into the same positions that they were removed from. 

% ---------------------
\subsection{Repair Heuristic}
\label{subsec:repairheuristic}

The repair heuristic used by the Enhanced Bees Algorithm randomly selects one of the removed customers $v_j$, and calculates a cost for reinserting $v_j$ between each pair of jobs $v_i, v_k \in R_i$ for all $R_i \in \schd$ (actually not all reinsertion positions are considered, see Section \ref{subsec:neighborhoodscope} for a description of which positions are considered). The reinsertion cost is calculated as follows:

\begin{align}
   c^*   &= c_{ij} + c_{jk} - c_{ik} \\
   cost  &= c^* + d(R') - d(R) + t(R') - t(R)
\end{align}

Where $c^*$ calculates the cost difference in terms of travel distance. $R$ and $R'$ are defined as the route before and after the customer is inserted, respectively. And functions $d(R)$ and $t(R)$ are all defined as they are in Section \ref{sec:problemrepresentation}. The final cost is the sum of the added travel distance and the two extra penalties, if the route is now overcapacity or over its maximum duration. The algorithm selects the position with the lowest insertion cost to reinsert the customer. This is repeated until all customers are reinserted into the solution. 

The reason that the order in which customers are reinserted is done randomly is that it adds a beneficial amount of noise to the heuristic. This ensures a healthy diversity of solutions are generated from the heuristic. 

% ---------------------
\subsection{Neighbourhood Extent}
\label{subsec:neighborhoodscope}

We also use two techniques that adjust the extent of the neighbourhood being searched. 

The first technique that we use is to allow the algorithm some flexibility in selecting infeasible solutions. As can be seen from our formulation of the candidate solutions' fitness values (see Section \ref{sec:problemrepresentation}) violations of the problem's capacity and duration constraints are penalised rather than forbidden. This allows the bees to navigate through infeasible solutions, where other aspects of that solution are sufficiently attractive enough to outweigh the penalties. However, only feasible solutions are allowed to be counted as final solutions returned by the algorithm. In Chapter \ref{chap:results} we show experimentally how much impact different values of the penalty constraints, $\alpha$, $\beta$, and $\gamma$, have on the performance of the algorithm.

Another technique that we use is to adjust the number of insertion positions considered as part of the repair heuristic. The number of insertion positions considered starts with both sides of the three closest customers and increases as the site ages. More formally, let $v_i \in V$ be the customer that is being inserted. An ordered sequence of candidate insertion points, $L_{v_i} = \seq{v_1,...,v_n}$ such that $v_j \in V - v_i$, is kept that lists customers in increasing geographic distance from $v_i$, that is $c_{ij} \forall j \in V - i$. The LNS repair operator tests $\mu$ positions from $L_{v_i}$ to find the cheapest insertion point. The repair operator tests both possible insertion points represented by $v_j \in L_{v_i}$, that is, it tests both the insertion cost of inserting $v_i$ immediately before and after $v_j$ in the route $R$ that contains $v_j$. 

For each site $s_i \in S$ we also maintain a counter $a_i, i \in S$ that denotes the age of the site. A site's age is incremented for each iteration that a site doesn't improve upon it currently best known solution (as defined by the solutions fitness, $f(\schd)$). Whenever a site improves upon its best known solution then the counter is reset, such that $a_i = 0$.

\picscl{images/neighbourhood.pdf}{The diagram shows a vertex being considered for reinsertion back into a solution. It starts by only considering insertion points that are geographically close to its position. The search area is widened over the course of the algorithm to take into consideration a larger set of insertion points.}{fig:neighbourhood}{0.85}

We then use the following formula to increase how much of $L_{v_i}$ is considered as the site ages.

\[
   \mu = \left|L_{v_i}\right| min\left(\frac{a_i}{k}, 1\right)
\]

Where $k$ is a constant that controls the rate at which the search area is expanded. 

As this process extends the number of insertion positions that are considered by the repair heuristic, this also serves to extend the neighbourhood of solutions surrounding a candidate solution $\schd$. In this way, we are also dynamically extending the size of a neighbourhood surrounding a site, $s_i \in S$, if $s_i$ becomes stuck in a local optimum.


