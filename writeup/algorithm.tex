%!TEX root = main.tex

% =====================
% CHAPTER
% ---------------------
% =====================
\chapter{Algorithm}

This chapter presents the algorithm used within this thesis and provides detailed technical description. Several novel concepts ... 

% TO SOLVE THE CVRP

% =====================
% SECTION
% =====================
\section{Goals}
The algorithm presented in this thesis was built for use in a commercial setting. It was developed as part of a NZTE grant for the company \emph{vWorkApp Inc.}'s scheduling and dispatch software. Accordingly more emphasis is given to runtime performance relative to optimisation performance, than is typically afforded in the \VRP\ literature.
 
The algorithm aims to achieves the following goals (in order of priority):

\begin{enumerate}
   \item All constraints meet. Specifically the maximum shift time for a route must be observed.
   \item Speed of execution. It was more important that the algorithm produces a result within 5\% of optimal quickly, than it achieves 99\% of optimal over a longer period of time. The algorithm has also been designed to allow for it to be easily parallelized, to take advantage of modern hardware.
   \item Travel distance is minimized.
\end{enumerate}

% =====================
% SECTION
% =====================
\section{Problem Representation}

Our algorithm represents the problem in a direct and straight forward manner. It proceeds by directly manipulating the candidate solution $\schd$, where $\schd$ is a set of routes $R \in \schd$, and each route contains an ordered sequence of customers $v_i \in R$ starting and ending at the depot vertex $v^d$.

\picscl{images/representation.pdf}{Shown is an example of a simple \VRP\ candidate solution as represented internally by the algorithm.}{fig:representation}{0.66}

More generic representations are sometimes used for meta-heuristics, as is commonly seen with Genetic Algorithms, as they allow the algorithm to be easily adapted to other combinatorial problems. This often comes at a cost of added complexity and often inferrer results\footnote{This occurs because the operators that act on the problem representation can no longer exploit information that is specific to the problem domain and must rely on general purpose operations instead}. This algorithm was designed specifically for solving instances of the \VRP\ so the direct representation was chosen. 

The algorithm makes use of a \emph{fitness} concept, common to many meta-heuristics, to describe the cost of the solution. Our fitness function $f()$ includes terms for the distance (i.e. cost) of the solution and penalties for breaking the capacity and maximum route time constraints. Specifically $f()$ is defined as follows:

\begin{align}
   & c(R) = \sum_{i \in R} c_{i, i+1} \\
   & d(R) = max( \sum_{i \in R} d_i - q, 0 )  \\
   & t(R) = max( \sum_{i \in R} t_i + c(R) - t, 0 )  \\
   & f(\schd) = \sum_{R \in \schd} (\alpha c(R) + \beta d(R) + \gamma c(R))
\end{align}

Function $c(R)$ calculates the cost (i.e distance) of a given route, function $d(R)$ calculates how overcapacity that the given route is. We define overcapacity to be how much larger the route's summed demands $d_i, i \in R$ are than the stated maximum allowable capacity $q$. Likewise function $t(R)$ calculates the overtime of the given route. A route's duration is calculated as being the sum of its customer's service times $t_i, i \in R$ and its travel time. By convention the travel time equal to the distance of the route. Function $t(R)$ then returns how much over the maximum allowable route duration $t$ the duration is. Lastly the fitness function $f()$ is the weighted sum of these three terms. Parameters $\alpha$, $\beta$, and $\gamma$ are used  used to control how influence each term has on determining the candidate solutions fitness.

For the purposes of benchmarking our algorithm (see chapter \ref{chap:results}) we use a travel cost that is equal to the 2D Euclidian distance \footnote{In this case we define the cost function as $c_{ij} = \sqrt{(x_j-x_i)^2 + (y_j-y_i)^2}$} between the two points. For real life problem instance we have found that using a manhattan distance\footnote{Conversely we use define the cost function as $c_{ij} = (x_j-x_i)^2 + (y_j-y_i)^2$} often provides superior results. This is presumably due to the manhattan distance better modeling the road system within Auckland, which although not a strict grid still doesn't allow line-of-site travel.


% =====================
% SECTION
% =====================
\section{Enhanced Bees Algorithm}

Our Algorithm is based on the \emph{Bees Algorithm} (see section \ref{subsec:beesalgorithm} for an overview of this algorithm). The algorithm makes some changes to adapt the Bees Algorithm to this domain. An interesting aspect of the Bees Algorithm is that it covers a broad search area, minimizing the risk of being stuck in a local optimum. It achieves this by randomly probing (or in the Bees Algorithm parlance, Scouting) many areas of the search space through its entire run. However, this approach isn't well suited to hard combinatorial problems, where a newly constructed solution, let alone a randomly constructed one, is often far from optimal (for instance, the Clark Wright Savings heuristic still produces solutions that are upto 15\% from the best known and will require many operations to get close to optimal). We've adapted the Bees Algorithm such that many of its unique characteristics, such as its broad coverage, are maintained while working well with hard combinatorial problem, such as the \VRP.

Our algorithm can be summarized at a high level as follows:

\begin{algorithm}[H]
   \caption{Enhanced Bees Algorithm}
   $S$ = seedSites() \\

   \While{termination condition not meet}{
      \For{$s_i \in S$}{
         explore($s_i$, $d$) \\
         \If{$i < \lambda$}
            killWorstSites \\
      }
   }
\end{algorithm}

The algorithm maintains a collection of sites $S$, and each site $s_i \in S$ maintains a collection of bees $B_i$. Each bee is a proxy to the problem domain that we're trying to solve. In our case this is the \VRP\ problem representation covered above.

== PIC OF BEE + SITES ==

Initially each site is seeded, such that each site $s_i \in S$ contains a collection of bees $B_i$, and each bee has a corresponding \VRP\ candidate solution $\schd$. Each candidate solution is initialized by seeding each route with a randomly chosen customer, and is then filled out using the insertion heuristic outlined in \ref{subsec:repairoperation}.

Each site is then, in turn, improved upon. This is achieved by iteratively exploring the neighbourhood of each site. The explore procedure for each neighbourhood is implemented as outlined in sections \ref{subsec:beemovement}, \ref{subsec:searchspacecoverage}, and \ref{sec:neighborhoodexploration}.

The number of sites explored is reduced over the run of the algorithm. This borrows from the idea of a cooling schedule used by Simulated Annealing. Sites are reduced using the formula:

\begin{align}
   & S = S - s_w & \text{if $t \text{ mod } \lambda = 0$}
\end{align}

Where $s_w$ represents the worst site, in terms of fitness, $i$ represents the current iteration of the algorithm, and $\lambda$ represents the period of iterations with which the number of sites are reduced. Once the algorithm is complete the $\schd$ with the best overall fitness is returned as the answer.

In the next section we review in more detail each aspect of the algorithm. 

% ---------------------
\subsection{Bee movements}
\label{beemovement}

Bees are moved around the search space to look for improvements to the collection of candidate solutions being maintained. Each bee represents a current solution $\schd$, so a valid bee move is any new candidate solution $\schd'$ that can be reached within the neighbourhood of $\schd$ (see \ref{subsec:neighborhood} for the operations under which the neighbourhood is defined).

\picscl{images/movement.pdf}{TODO.}{fig:movement}{0.90}

A feature of our algorithm is that two Bees can't occupy the same position. The algorithm maintains a register of the current positions occupied by each bee. We use the current fitness, $f(\schd)$, as a quick and simple representation of a bees current position\footnote{This obviously won't work in circumstances where there is a reasonable likelihood of two candidate solutions, $\schd_i$ and $\schd_j$ having $f(\schd_i) = f(\schd_j)$. This isn't the case with the problem instances we've used in this thesis. However, this will need to be modified if the algorithm is to be used on more general problem instances}. If a bee tries to occupy the same position as another bee (i.e. they share the same candidate solution) then the bee trying to occupy that position is forced to explore the neighbourhood again and find another position. 

This position scheme has two benefits. It forces diversification between the bees and sites, increasing the likelihood that new positions are found and that 

% SAY SOMETHING ABOUT SITES vs BACKS
% The population of bees is also segmented into sites, where each site maintains a best known candidate solution. 

% TABU LIST
% - Keep over bees separate. Bee sites seperate. 
% - Operates as divivication mechanism

% BACKLIST OF LAST x BEST PATH, used as launching point for next explore

% ---------------------
\subsection{Search space coverage}
\label{subsec:searchspacecoverage}

% - Broadsearch start
% - The problem with sending bees out to find random sites, and lopsided search, and how we fix it (aging of sites)
% ---------------------


% =====================
% SECTION
% =====================
\section{Neighborhood Exploration}
\label{sec:neighborhoodexploration}

% ---------------------
\subsection{Wriggle room with capacity constraints}

% ---------------------
\subsection{Neighborhood}
\label{subsec:neighborhood}

% - Takes advantage of Taillards observation that the move between tours don't need to be huge. It is suffient to move to the tour in an adjoining segment. This is achieved here by the NEAREST cities list, and much simplier and quicker.

% - Circles. Expands as search deepens


% ---------------------
\subsection{Destroy operation}

% - Worst
% - Random

% - Avoid the problem of Tabu Search moving cities around the depot more frequently, because removes are random. \cite{Taillard:1993}.

% dependent on how the partial solution is repaired. Shaw [51] proposed to gradually increase the degree of destruction, while Ropke and Pisinger [45] choose the degree of destruction randomly in each iteration by choosing the degree from a specific range dependent on the instance size. The destroy method must also be chosen such

% ---------------------
\subsection{Repair operation}
\label{subsec:repairoperation}

% - Random best (random order)

% - Candidate lists

    % However, from a diversification point of view, an optimal repair operation may not be attractive: only improving or identical-cost solutions will be produced


% == TO TRY ==

% Expanding a neighbourhood as a site ages
% Various neighbourhoods ( remove worst? insert total best? 2-opt? lambda-opt? )
% Apative memory (i.e. combining best solutions + killing ages ones)


